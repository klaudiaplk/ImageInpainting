{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtq9drjLy5Jl"
      },
      "source": [
        "# Coherent Semantic Attention - PyTorch Implementation\n",
        "\n",
        "Student: Klaudia Palak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXWF9Hqry0QW"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_Bafd01zPwq"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqAdXY2vzSS_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8Xhlm_8zURi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,\"/content/drive/My Drive/Magisterka/Coherent_Semantic_Attention_code\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtEr16TBzYIT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output \n",
        "# Unzip file - if you use Google GPU\n",
        "!unrar e \"/content/drive/My Drive/Magisterka/Coherent_Semantic_Attention_code/mask_dataset.rar\" /content/mask/\n",
        "!unzip \"/content/drive/My Drive/Magisterka/Coherent_Semantic_Attention_code/paris_train_original.zip\" -d /content/train_dataset/\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKwqyIYAzY2v"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TXJNNMvza7H"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "from utils.data_load import DataLoad\n",
        "import os\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enO35StrzfJj"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_-_E6pnzc5A"
      },
      "outputs": [],
      "source": [
        "class Opion():\n",
        "    \n",
        "    def __init__(self):\n",
        "            \n",
        "        self.dataroot= r'/content/train_dataset/paris_train_original' # image dataroot\n",
        "        self.maskroot= r'/content/mask'# mask dataroot\n",
        "        self.batchSize= 1   # Need to be set to 1\n",
        "        self.fineSize=256 # image size\n",
        "        self.input_nc=3  # input channel size for first stage\n",
        "        self.input_nc_g=6 # input channel size for second stage\n",
        "        self.output_nc=3 # output channel size\n",
        "        self.ngf=64 # inner channel\n",
        "        self.ndf=64 # inner channel\n",
        "        self.which_model_netD='basic' # patch discriminator\n",
        "        self.which_model_netF='feature'# feature patch discriminator\n",
        "        self.which_model_netG='unet_csa'# seconde stage network\n",
        "        self.which_model_netP='unet_256'# first stage network\n",
        "        self.triple_weight=1\n",
        "        self.name='CSA_inpainting'\n",
        "        self.n_layers_D='3' # network depth\n",
        "        self.gpu_ids=[0]\n",
        "        self.model='csa_net'\n",
        "        self.checkpoints_dir=r'/content/drive/MyDrive/Magisterka/Coherent_Semantic_Attention_code/checkpoints' # checkpoints folder\n",
        "        self.norm='instance'\n",
        "        self.fixed_mask=1\n",
        "        self.use_dropout=False\n",
        "        self.init_type='normal'\n",
        "        self.mask_type='random' # or 'center'\n",
        "        self.lambda_A=100\n",
        "        self.threshold=5/16.0\n",
        "        self.stride=1\n",
        "        self.shift_sz=1 # size of feature patch\n",
        "        self.mask_thred=1\n",
        "        self.bottleneck=512\n",
        "        self.gp_lambda=10.0\n",
        "        self.ncritic=5\n",
        "        self.constrain='MSE'\n",
        "        self.strength=1\n",
        "        self.init_gain=0.02\n",
        "        self.cosis=1\n",
        "        self.gan_type='lsgan'\n",
        "        self.gan_weight=0.2 # the weight with which the GAN loss function is taken into account in the calculation of the total generator loss\n",
        "        self.ssim_weight = 100 # the weight with which the SSIM loss function is taken into account in the calculation of the total generator loss\n",
        "        self.lorentzian_weight = 10 # the weight with which the Lorentzian loss function is taken into account in the calculation of the total generator loss\n",
        "        self.overlap=4\n",
        "        self.skip=0\n",
        "        self.display_freq = 100\n",
        "        self.print_freq = 2\n",
        "        self.save_latest_freq = 5\n",
        "        self.save_epoch_freq=1\n",
        "        self.continue_train=True\n",
        "        self.epoch_count=1\n",
        "        self.phase='train'\n",
        "        self.which_epoch=''\n",
        "        self.niter = 20\n",
        "        self.niter_decay = 100\n",
        "        self.beta1=0.5\n",
        "        self.lr=0.0002\n",
        "        self.lr_policy='lambda'\n",
        "        self.lr_decay_iters=50\n",
        "        self.isTrain=True\n",
        "        self.ssim_loss=True # True or False if we want to use / don't use SSIM loss additionally\n",
        "        self.lorentzian_loss=False # True or False if we want to use / don't use Lorentzian loss additionally\n",
        "        self.l1_weight=0.1 # similarly (1-self.l1_weight) for SSIM loss, SSIM i L1 loss sum up to 1\n",
        "        \n",
        "        # Parametry, które odpowiadają za dotrenowywanie sieci dalej:\n",
        "#         self.which_epoch='10' # numer ostatniej epoki, którą wytranował i której modele znajdują się w folderze checkpoints\n",
        "#         self.continue_train=True\n",
        "#         self.epoch_count=11 # numer kolejnej epoki, od której ma zacząć trenować dalej"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eazr68eyziZd"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKCP69XGzhrD"
      },
      "outputs": [],
      "source": [
        "opt = Opion()\n",
        "transform_mask = transforms.Compose(\n",
        "    [transforms.Resize((opt.fineSize,opt.fineSize)),\n",
        "     transforms.ToTensor(),\n",
        "    ])\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(),\n",
        "     transforms.Resize((opt.fineSize,opt.fineSize)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)])\n",
        "\n",
        "dataset_train = DataLoad(opt.dataroot, opt.maskroot, transform, transform_mask)\n",
        "iterator_train = (data.DataLoader(dataset_train, batch_size=opt.batchSize,shuffle=True))\n",
        "print(len(dataset_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BopSS787znUe"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2sUN0D3zpzB"
      },
      "outputs": [],
      "source": [
        "from models.model import create_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ztm39pKzzrM"
      },
      "outputs": [],
      "source": [
        "model = create_model(opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ67lWEwz6MJ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1y9nGXDz1rQ"
      },
      "outputs": [],
      "source": [
        "stotal_steps = 0\n",
        "iter_start_time = time.time()\n",
        "\n",
        "# Dictionary for evaluation metrics\n",
        "evaluation_metrics = {\"loss_G_GAN\":[], \"loss_G_L1\":[], \"loss_G_SSIM\":[], \"loss_G_Lorentzian\":[], \n",
        "                      \"loss_D\":[], \"loss_D_Lorentzian\":[], \"loss_F\":[], \"loss_D_overall\":[], \"loss_G_overall\":[]}\n",
        "\n",
        "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
        "    \n",
        "    epoch_start_time = time.time()\n",
        "    epoch_iter = 0\n",
        "\n",
        "    for image, mask in (iterator_train):\n",
        "        image=image.cuda()\n",
        "        mask=mask.cuda()\n",
        "        mask=mask[0][0]\n",
        "        mask=torch.unsqueeze(mask,0)\n",
        "        mask=torch.unsqueeze(mask,1)\n",
        "        mask=mask.byte()\n",
        "\n",
        "        total_steps += opt.batchSize\n",
        "        epoch_iter += opt.batchSize\n",
        "        model.set_input(image,mask) # it not only sets the input data with mask, but also sets the latent mask.\n",
        "        model.set_gt_latent()\n",
        "        model.optimize_parameters()\n",
        "\n",
        "        if total_steps % opt.display_freq == 0:\n",
        "            real_A,real_B,fake_B=model.get_current_visuals()\n",
        "            #real_A=input, real_B=ground truth fake_b=output\n",
        "            pic = (torch.cat([real_A, real_B,fake_B], dim=0) + 1) / 2.0\n",
        "            torchvision.utils.save_image(pic, '%s/Epoch_(%d)_(%dof%d).jpg' % (\n",
        "            opt.checkpoints_dir, epoch, total_steps + 1, len(dataset_train)), nrow=2)\n",
        "        if total_steps %1== 0:\n",
        "            errors = model.get_current_errors()\n",
        "            # Add errors to dictionary\n",
        "            evaluation_metrics[\"loss_G_GAN\"].append(errors[\"G_GAN\"])\n",
        "            evaluation_metrics[\"loss_G_L1\"].append(errors[\"G_L1\"])\n",
        "            evaluation_metrics[\"loss_D\"].append(errors[\"D\"])\n",
        "            if opt.lorentzian_loss:\n",
        "                evaluation_metrics[\"loss_G_Lorentzian\"].append(errors[\"G_Lorentzian\"])\n",
        "                evaluation_metrics[\"loss_D_Lorentzian\"].append(errors[\"D_Lorentzian\"])\n",
        "            if opt.ssim_loss:\n",
        "                evaluation_metrics[\"loss_G_SSIM\"].append(errors[\"G_SSIM\"])\n",
        "            # Add overall errors for G and D\n",
        "            evaluation_metrics[\"loss_F\"].append(errors[\"F\"])\n",
        "            evaluation_metrics[\"loss_D_overall\"].append(errors[\"D_overall\"])\n",
        "            evaluation_metrics[\"loss_G_overall\"].append(errors[\"G_overall\"])\n",
        "            t = (time.time() - iter_start_time) / opt.batchSize\n",
        "            print(errors)\n",
        "\n",
        "    if epoch % opt.save_epoch_freq == 0:\n",
        "        print('saving the model at the end of epoch %d, iters %d' %\n",
        "                (epoch, total_steps))\n",
        "        model.save(epoch)\n",
        "\n",
        "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
        "            (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
        "\n",
        "    model.update_learning_rate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-FA-oFrz_5h"
      },
      "source": [
        "# Visualization of training losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUpkBKD10Ahc"
      },
      "outputs": [],
      "source": [
        "# Check mean values for evaluation metrics\n",
        "loss_G_GAN = sum(evaluation_metrics[\"loss_G_GAN\"]) / len(evaluation_metrics[\"loss_G_GAN\"])\n",
        "print(\"Mean value for G GAN loss is: {}\".format(loss_G_GAN))\n",
        "loss_G_L1 = sum(evaluation_metrics[\"loss_G_L1\"]) / len(evaluation_metrics[\"loss_G_L1\"])\n",
        "print(\"Mean value for G L1 loss is: {}\".format(loss_G_L1))\n",
        "loss_D = sum(evaluation_metrics[\"loss_D\"]) / len(evaluation_metrics[\"loss_D\"])\n",
        "print(\"Mean value for D loss is: {}\".format(loss_D))\n",
        "\n",
        "if opt.lorentzian_loss:\n",
        "    loss_G_Lorentzian = sum(evaluation_metrics[\"loss_G_Lorentzian\"]) / len(evaluation_metrics[\"loss_G_Lorentzian\"])\n",
        "    print(\"Mean value for G Lorentzian loss is: {}\".format(loss_G_Lorentzian))\n",
        "    loss_D_Lorentzian = sum(evaluation_metrics[\"loss_D_Lorentzian\"]) / len(evaluation_metrics[\"loss_D_Lorentzian\"])\n",
        "    print(\"Mean value for D Lorentzian loss is: {}\".format(loss_D_Lorentzian))\n",
        "if opt.ssim_loss:\n",
        "    loss_G_SSIM = sum(evaluation_metrics[\"loss_G_SSIM\"]) / len(evaluation_metrics[\"loss_G_SSIM\"])\n",
        "    print(\"Mean value for G SSIM loss is: {}\".format(loss_G_SSIM))\n",
        "\n",
        "loss_F = sum(evaluation_metrics[\"loss_F\"]) / len(evaluation_metrics[\"loss_F\"])\n",
        "print(\"Mean value for F overall loss is: {}\".format(loss_F))\n",
        "loss_D_overall = sum(evaluation_metrics[\"loss_D_overall\"]) / len(evaluation_metrics[\"loss_D_overall\"])\n",
        "print(\"Mean value for D overall loss is: {}\".format(loss_D_overall))\n",
        "loss_G_overall = sum(evaluation_metrics[\"loss_G_overall\"]) / len(evaluation_metrics[\"loss_G_overall\"])\n",
        "print(\"Mean value for G overall loss is: {}\".format(loss_G_overall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxXkhOgj0D35"
      },
      "outputs": [],
      "source": [
        "def save_path(save_dir, loss_name):\n",
        "    if os.path.exists(save_dir) is False:\n",
        "        os.makedirs(save_dir)\n",
        "    save_filename = '%s_plot.png' % (loss_name)\n",
        "    save_path = os.path.join(save_dir, save_filename)\n",
        "    return save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DqFGimO0F_t"
      },
      "outputs": [],
      "source": [
        "def loss_plot(evaluation_metrics_list, loss_name):\n",
        "    counter = [x for x in range(1, len(evaluation_metrics_list)+1)]\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=counter, y=evaluation_metrics_list, mode='lines', name=loss_name))\n",
        "\n",
        "    fig.update_layout(\n",
        "        width=1000,\n",
        "        height=500,\n",
        "        title=loss_name,\n",
        "        xaxis_title=\"Number of training examples seen\",\n",
        "        yaxis_title=loss_name),\n",
        "    fig.show()\n",
        "    # path = save_path(opt.checkpoints_dir, loss_name)\n",
        "    # fig.write_image(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnWCFadp0IMe"
      },
      "outputs": [],
      "source": [
        "loss_plot(evaluation_metrics[\"loss_G_GAN\"], \"Generator Adversarial Loss\")\n",
        "loss_plot(evaluation_metrics[\"loss_G_L1\"], \"Generator L1 Loss\")\n",
        "loss_plot(evaluation_metrics[\"loss_D\"], \"Patch Discriminator Adversarial Loss\")\n",
        "if opt.lorentzian_loss:\n",
        "    loss_plot(evaluation_metrics[\"loss_G_Lorentzian\"], \"Generator Lorentzian Loss\")\n",
        "    loss_plot(evaluation_metrics[\"loss_D_Lorentzian\"], \"Patch Discriminator Lorentzian Loss\")\n",
        "if opt.ssim_loss:\n",
        "    loss_plot(evaluation_metrics[\"loss_G_SSIM\"], \"Generator SSIM Loss\")\n",
        "\n",
        "loss_plot(evaluation_metrics[\"loss_F\"], \"Feature Discriminator Overall Loss\")\n",
        "loss_plot(evaluation_metrics[\"loss_D_overall\"], \"Patch Discriminator Overall Loss\")\n",
        "loss_plot(evaluation_metrics[\"loss_G_overall\"], \"Generator Overall Loss\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}